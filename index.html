<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- --- SEO & SOCIAL PREVIEW --- -->
    <title>AI THINGS</title>
    <meta name="description" content="Esplora l'ecosistema AI: dai repository Core agli stack delle Big Tech. Una mappa interattiva per sviluppatori e ricercatori.">
    <meta name="author" content="Giacomo Marani">

    <!-- FAVICON -->
    <link rel="icon" href="logo.ico" type="image/x-icon">
    <link rel="shortcut icon" href="logo.ico" type="image/x-icon">

    <!-- Open Graph / Facebook / LinkedIn -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://giacomomarani.github.io/AI-THINGS/"> 
    <meta property="og:title" content="AI THINGS // Knowledge Explorer">
    <meta property="og:description" content="Esplora l'ecosistema AI: dai repository Core agli stack delle Big Tech. Una mappa interattiva per sviluppatori.">
    <meta property="og:image" content="https://raw.githubusercontent.com/GiacomoMarani/AI-THINGS/main/preview.png"> 

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://giacomomarani.github.io/AI-THINGS/">
    <meta property="twitter:title" content="AI THINGS // Knowledge Explorer">
    <meta property="twitter:description" content="Esplora l'ecosistema AI: dai repository Core agli stack delle Big Tech. Una mappa interattiva per sviluppatori.">
    <meta property="twitter:image" content="https://raw.githubusercontent.com/GiacomoMarani/AI-THINGS/main/preview.png">

    <!-- --- ASSETS --- -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <style>
        /* --- CORE VISUALS --- */
        body {
            font-family: 'IBM Plex Mono', monospace;
            background-color: #050505;
            color: #e0e0e0;
            overflow-x: hidden;
            background-image: 
                linear-gradient(rgba(0, 255, 255, 0.03) 1px, transparent 1px), 
                linear-gradient(90deg, rgba(0, 255, 255, 0.03) 1px, transparent 1px);
            background-size: 40px 40px;
        }

        /* --- SCROLLBAR (CYAN) --- */
        ::-webkit-scrollbar { width: 8px; height: 4px; }
        ::-webkit-scrollbar-track { background: #0a0a0f; }
        ::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: #00FFFF; }

        /* --- GLASS PANELS (CYAN TINT) --- */
        .bg-glass {
            background: rgba(10, 10, 15, 0.85);
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border: 1px solid rgba(0, 255, 255, 0.1);
            box-shadow: 0 4px 30px rgba(0, 0, 0, 0.5);
        }

        /* --- INTERACTIVE ELEMENTS (CYAN HOVER) --- */
        .bg-interactive {
            background: rgba(17, 17, 22, 0.6);
            border: 1px solid rgba(255, 255, 255, 0.05);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }
        .bg-interactive:hover {
            background: rgba(20, 20, 30, 0.8);
            border-color: #00FFFF;
            box-shadow: 0 0 15px rgba(0, 255, 255, 0.15);
            transform: translateY(-2px);
        }

        /* --- BRIEFING PANEL (CYAN) --- */
        .briefing-panel {
            background: rgba(0, 255, 255, 0.05);
            border-left: 4px solid #00FFFF;
            padding: 1rem;
            margin-bottom: 2rem;
            border-radius: 0 8px 8px 0;
            font-size: 0.9rem;
            line-height: 1.6;
            color: #ccc;
        }
        .briefing-title {
            color: #00FFFF;
            font-weight: bold;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 0.5rem;
            display: block;
        }

        /* --- INSIGHT BOX --- */
        .insight-box {
            margin-top: 12px;
            padding: 8px 12px;
            background: rgba(255, 215, 0, 0.05);
            border-left: 2px solid #FFD700;
            color: #e0e0e0;
            font-size: 0.75rem;
            font-family: sans-serif;
            font-style: italic;
        }

        /* --- NEON TEXT --- */
        .neon-blue { color: #00FFFF; text-shadow: 0 0 8px rgba(0, 255, 255, 0.5); }
        .neon-pink { color: #FF00FF; text-shadow: 0 0 8px rgba(255, 0, 255, 0.5); }
        
        /* --- STRANGER THINGS NEON (TITLE ONLY) --- */
        .neon-stranger {
            font-family: 'IBM Plex Mono', monospace;
            color: #E72429;
            text-shadow: 
                0 0 5px #E72429,
                0 0 15px #ff0000,
                0 0 30px #E72429;
            -webkit-text-stroke: 1px rgba(231, 36, 41, 0.3);
        }

        .neon-stranger-subtitle {
            font-family: 'IBM Plex Mono', monospace;
            color: #E72429;
            text-shadow: 
                0 0 3px #E72429,
                0 0 10px rgba(231, 36, 41, 0.8);
        }

        /* --- BUTTONS (MENU STYLE - RED NEON - RESTORED) --- */
        .btn-category {
            @apply px-6 py-3 text-xs sm:text-sm font-bold uppercase tracking-[0.15em] transition-all duration-200 relative whitespace-nowrap;
            background: transparent; 
            color: #6b7280; 
            border: none;
            border-radius: 0;
        }

        .btn-category:hover {
            color: #e5e7eb;
            background: rgba(231, 36, 41, 0.1); 
            text-shadow: 0 0 5px rgba(231, 36, 41, 0.4);
        }

        .btn-category.active {
            background: rgba(231, 36, 41, 0.05); 
            color: #E72429; /* RED TEXT */
            border-top: 2px solid #E72429; /* RED LINE */
            border-bottom: 2px solid #E72429; /* RED LINE */
            box-shadow: 0 0 15px rgba(231, 36, 41, 0.2);
            text-shadow: 0 0 8px rgba(231, 36, 41, 0.6);
        }

        /* --- SEARCH BUTTON --- */
        .btn-search {
            background: linear-gradient(90deg, #FF00FF, #cc00cc);
            color: #fff;
            font-weight: 800;
            border: none;
            border-radius: 4px;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .btn-search:hover { filter: brightness(1.2); box-shadow: 0 0 15px rgba(255, 0, 255, 0.4); }
        
        .btn-guide {
            color: #6b7280;
            border: 1px solid #374151;
            background: rgba(0,0,0,0.5);
            transition: all 0.2s;
        }
        .btn-guide:hover {
            color: #00FFFF;
            border-color: #00FFFF;
            text-shadow: 0 0 5px #00FFFF;
        }

        /* --- INPUTS (CYAN) --- */
        .input-cyber {
            background: rgba(15, 15, 19, 0.9);
            border: 1px solid #374151;
            color: #00FFFF;
            transition: 0.3s;
        }
        .input-cyber:focus { outline: none; border-color: #FF00FF; background: #000; box-shadow: 0 0 10px rgba(255, 0, 255, 0.2); }
        
        .select-view {
            background: #000;
            color: #FF00FF;
            border: 1px solid #FF00FF;
            font-weight: bold;
            padding: 0.5rem 1rem;
            cursor: pointer;
            outline: none;
        }

        /* --- LANGUAGE TOGGLE --- */
        .lang-toggle {
            font-size: 0.75rem;
            color: #666;
            cursor: pointer;
            margin-left: 10px;
            font-weight: bold;
        }
        .lang-toggle.active { color: #00FFFF; text-shadow: 0 0 5px #00FFFF; }

        /* --- ANIMATIONS --- */
        @keyframes fadeSlideIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .animate-entry { animation: fadeSlideIn 0.4s ease-out forwards; }
        
        /* Modal Overlay */
        .modal-overlay {
            background: rgba(0, 0, 0, 0.85);
            backdrop-filter: blur(5px);
            z-index: 50;
        }
        
        .hidden { display: none; }
    </style>
</head>
<body class="min-h-screen p-2 sm:p-6 lg:p-8">

    <div class="max-w-7xl mx-auto">
        
        <div class="bg-glass rounded-2xl p-6 sm:p-8 relative min-h-[85vh] flex flex-col">
            
            <div class="absolute top-0 left-0 w-full h-[2px] bg-gradient-to-r from-transparent via-cyan-500 to-transparent opacity-70"></div>

            <!-- HEADER -->
            <header class="flex flex-col lg:flex-row justify-between items-start lg:items-center mb-8 border-b border-gray-800 pb-6 gap-6">
                <div>
                    <h1 class="text-3xl sm:text-4xl lg:text-5xl font-bold neon-stranger tracking-tighter mb-1">
                        // AI THINGS
                    </h1>
                    <p class="text-[10px] sm:text-xs neon-stranger-subtitle italic tracking-widest mb-2 opacity-90 font-bold">
                        'Cause I believe in a better way
                    </p>

                    <div class="flex items-center gap-3 mt-2 flex-wrap">
                        <div id="api-status-dot" class="w-2 h-2 rounded-full bg-green-400 shadow-[0_0_10px_#4ade80]"></div>
                        <span class="text-xs text-gray-400 font-mono tracking-widest" data-i18n="system_status">SYSTEM_STATUS: ONLINE</span>
                        
                        <!-- Guide Button -->
                        <button id="btn-open-guide" class="btn-guide px-2 py-0.5 ml-2 text-[10px] rounded uppercase font-bold tracking-wider">
                            [?] <span data-i18n="guide_btn">GUIDE</span>
                        </button>

                        <div class="flex items-center border-l border-gray-700 pl-3 ml-2">
                            <span class="lang-toggle" id="lang-en" onclick="setLanguage('en')">EN</span>
                            <span class="text-gray-700 mx-1">/</span>
                            <span class="lang-toggle" id="lang-it" onclick="setLanguage('it')">IT</span>
                        </div>
                    </div>
                </div>

                <div class="w-full lg:w-auto">
                    <label class="text-[10px] text-gray-500 font-bold uppercase tracking-[0.2em] mb-2 block" data-i18n="view_label">MODALITÀ</label>
                    <select id="view-selector" class="select-view w-full lg:w-auto uppercase tracking-widest text-sm rounded h-10">
                        <option value="explorer">⦿ KNOWLEDGE EXPLORER</option>
                        <option value="titans">⟁ CORPORATE STACKS</option>
                        <option value="mcp">↯ MCP PROTOCOL</option>
                        <option value="docs">▤ OFFICIAL DOCS</option>
                    </select>
                </div>
            </header>

            <!-- ========================================== -->
            <!-- VISTA 1: REPO EXPLORER -->
            <!-- ========================================== -->
            <section id="view-explorer" class="view-section flex-grow">
                <!-- MENU SPAZIATO E CENTRATO -->
                <div class="mb-6">
                    <div id="category-buttons" class="flex flex-wrap gap-x-6 gap-y-4 border-b border-gray-800 pb-6 justify-center"></div>
                </div>

                <div id="explorer-briefing" class="briefing-panel animate-entry hidden">
                    <span class="briefing-title">// MISSION BRIEFING</span>
                    <p id="explorer-briefing-text">...</p>
                </div>

                <!-- SEARCH BAR (NO WRAP) -->
                <div class="mb-8 relative group">
                    <div class="absolute -inset-0.5 bg-gradient-to-r from-pink-600 to-cyan-600 rounded-lg blur opacity-30 group-hover:opacity-60 transition duration-500"></div>
                    <div class="relative flex flex-row gap-0 bg-black rounded-lg p-1">
                        <input type="text" id="search-input" placeholder="..." class="input-cyber flex-1 px-4 py-3 rounded-md text-sm font-mono placeholder-gray-600 border-none min-w-0">
                        <button id="execute-query-button" class="btn-search w-14 flex-shrink-0 flex items-center justify-center rounded-md hover:scale-105 transition-transform" aria-label="Search">
                            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2.5" stroke="currentColor" class="w-5 h-5 text-white">
                                <path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z" />
                            </svg>
                        </button>
                    </div>
                </div>
                
                <div class="flex items-end justify-between mb-6 pl-4 border-l-4 border-pink-500">
                    <div>
                        <h2 class="text-2xl font-bold text-white uppercase tracking-tight leading-none" id="results-title">...</h2>
                        <p class="text-xs text-cyan-400 font-mono mt-2 tracking-wide" id="results-subtitle">...</p>
                    </div>
                </div>

                <div id="loading-spinner-exp" class="hidden text-center py-12">
                    <div class="animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-cyan-400 mx-auto shadow-[0_0_20px_#00FFFF]"></div>
                    <p class="text-cyan-500 mt-4 text-xs font-mono animate-pulse" data-i18n="loading">LOADING INTELLIGENCE...</p>
                </div>
                
                <div id="results-container" class="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-2 gap-4 min-h-[200px]"></div>
            </section>

            <!-- ========================================== -->
            <!-- VISTA 2: TITANS -->
            <!-- ========================================== -->
            <section id="view-titans" class="view-section hidden flex-grow">
                <!-- MENU SPAZIATO E CENTRATO -->
                <div class="mb-6">
                    <h2 class="text-[10px] text-gray-500 font-bold uppercase tracking-[0.2em] mb-3 text-center" data-i18n="select_player">SELECT PLAYER</h2>
                    <div id="titans-buttons" class="flex flex-wrap gap-x-6 gap-y-4 border-b border-gray-800 pb-6 justify-center"></div>
                </div>

                <div id="titan-briefing" class="briefing-panel animate-entry hidden">
                    <span class="briefing-title" id="titan-briefing-title">// CORPORATE INTEL</span>
                    <p id="titan-briefing-text">...</p>
                </div>

                <div class="mb-8 p-4 bg-gray-900/50 rounded border border-gray-800 flex items-center justify-between">
                    <div>
                        <h3 class="text-lg font-bold neon-pink" id="titan-header-name">...</h3>
                    </div>
                    <div class="h-8 w-8 rounded bg-gray-800 flex items-center justify-center border border-gray-600 text-xs text-gray-400 font-mono" id="titan-logo-placeholder">AI</div>
                </div>

                <div id="loading-spinner-titans" class="hidden text-center py-20">
                    <div class="relative w-16 h-16 mx-auto">
                        <div class="absolute inset-0 border-4 border-pink-500/30 rounded-full animate-ping"></div>
                        <div class="absolute inset-0 border-4 border-t-pink-500 rounded-full animate-spin"></div>
                    </div>
                </div>

                <div id="titans-container" class="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-2 gap-4 min-h-[200px]"></div>
            </section>

             <!-- ========================================== -->
            <!-- VISTA 3: MCP PROTOCOL -->
            <!-- ========================================== -->
            <section id="view-mcp" class="view-section hidden flex-grow">
                <div class="mb-8">
                    <div id="mcp-briefing" class="briefing-panel animate-entry" style="border-left-color: #FFD700; background: rgba(255, 215, 0, 0.05);">
                        <span class="briefing-title" style="color: #FFD700;">// WHAT IS MCP?</span>
                        <p id="mcp-briefing-text" class="text-sm leading-relaxed">
                            <!-- Text injected via JS -->
                        </p>
                    </div>
                </div>
                
                <div class="flex items-end justify-between mb-6 pl-4 border-l-4 border-yellow-500">
                    <div>
                        <h2 class="text-2xl font-bold text-white uppercase tracking-tight leading-none">MCP SERVERS</h2>
                        <p class="text-xs text-yellow-500 font-mono mt-2 tracking-wide">// AGENTIC INFRASTRUCTURE BRIDGE</p>
                    </div>
                </div>

                <div id="mcp-container" class="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-2 gap-4 min-h-[200px]">
                     <!-- Cards injected via JS -->
                </div>
            </section>

             <!-- ========================================== -->
            <!-- VISTA 4: OFFICIAL DOCS -->
            <!-- ========================================== -->
            <section id="view-docs" class="view-section hidden flex-grow">
                <div class="mb-8">
                    <div id="docs-briefing" class="briefing-panel animate-entry" style="border-left-color: #A855F7; background: rgba(168, 85, 247, 0.05);">
                        <span class="briefing-title" style="color: #A855F7;">// DOCUMENTATION HUB</span>
                        <p id="docs-briefing-text" class="text-sm leading-relaxed">
                             <!-- Text injected via JS -->
                        </p>
                    </div>
                </div>

                <div class="flex items-end justify-between mb-6 pl-4 border-l-4 border-purple-500">
                    <div>
                        <h2 class="text-2xl font-bold text-white uppercase tracking-tight leading-none">OFFICIAL REFERENCES</h2>
                        <p class="text-xs text-purple-500 font-mono mt-2 tracking-wide">// DIRECT LINK UPLINK</p>
                    </div>
                </div>

                <div id="docs-container" class="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-2 gap-6 min-h-[200px]">
                    <!-- Cards injected via JS -->
                </div>
            </section>


            <div id="error-container" class="hidden mb-4 p-4 border border-red-500/50 bg-red-900/10 rounded text-red-400 text-sm font-mono mt-4"></div>

            <footer class="mt-16 border-t border-gray-800 pt-6 text-center">
                <p class="text-[10px] sm:text-xs font-mono text-gray-600 uppercase tracking-widest">
                    <span data-i18n="author_note">SYSTEM ARCHITECT:</span> 
                    <a href="https://www.linkedin.com/in/giacomo-marani-3a4532121/" target="_blank" class="text-cyan-500 hover:text-cyan-300 hover:shadow-[0_0_15px_#22d3ee] transition-all duration-300 font-bold ml-1 border-b border-gray-800 hover:border-cyan-400 pb-0.5">
                        GIACOMO MARANI
                    </a>
                </p>
            </footer>

        </div>
    </div>

    <!-- GUIDE MODAL -->
    <div id="guide-modal" class="modal-overlay fixed inset-0 flex items-center justify-center hidden p-4">
        <div class="bg-[#0a0a0f] border border-cyan-500 rounded-lg max-w-lg w-full p-6 shadow-[0_0_30px_rgba(0,255,255,0.2)] relative animate-entry">
            <button id="btn-close-guide" class="absolute top-4 right-4 text-gray-500 hover:text-cyan-500 text-xl font-bold">&times;</button>
            <h2 class="text-xl font-bold neon-blue mb-4 tracking-widest" data-i18n="guide_title">// SYSTEM MANUAL</h2>
            <div class="space-y-4 text-sm text-gray-300 font-mono leading-relaxed">
                <p data-i18n="guide_intro">...</p>
                <div class="p-3 bg-gray-900 border-l-2 border-pink-500"><p data-i18n="guide_mode_1">...</p></div>
                <div class="p-3 bg-gray-900 border-l-2 border-cyan-500"><p data-i18n="guide_mode_2">...</p></div>
                <div class="p-3 bg-gray-900 border-l-2 border-yellow-500"><p data-i18n="guide_mode_3">...</p></div>
                <div class="p-3 bg-gray-900 border-l-2 border-purple-500"><p data-i18n="guide_mode_4">...</p></div>
            </div>
            <div class="mt-6 text-center"><span class="text-[10px] text-gray-600 uppercase tracking-[0.2em]">ACCESS GRANTED</span></div>
        </div>
    </div>

    <script>
        // --- GLOBAL STATE ---
        let currentLang = 'en'; // Default fallback
        const CACHE = {};

        // --- I18N DICTIONARY ---
        const I18N = {
            it: {
                system_status: "STATO_SISTEMA: ONLINE", view_label: "MODALITÀ", select_player: "SELEZIONA PLAYER", search_placeholder: "ACCESS DATABASE: Cerca concetti...", init_title: "Inizializzazione...", init_subtitle: "// ATTENDERE INPUT", loading: "CARICAMENTO INTELLIGENCE...", no_data: "NESSUN DATO TROVATO.", no_result: "NESSUN RISULTATO.", insight_label: "INSIGHT:", rate_limit: "⚠️ RATE LIMIT GITHUB RAGGIUNTO.", author_note: "SVILUPPATO DA:", guide_btn: "GUIDA",
                guide_title: "// MANUALE SISTEMA", guide_intro: "Benvenuto in AI THINGS. Naviga l'ecosistema AI.", guide_mode_1: "<strong>KNOWLEDGE EXPLORER:</strong> Librerie Open Source, Framework e Guide.", guide_mode_2: "<strong>CORPORATE STACKS:</strong> Analisi delle Big Tech.", guide_mode_3: "<strong>MCP PROTOCOL:</strong> Lo standard per connettere LLM a dati reali.", guide_mode_4: "<strong>OFFICIAL DOCS:</strong> Accesso rapido a manuali e API ufficiali.",
                mcp_briefing: "MCP (Model Context Protocol) è uno standard aperto che agisce da ponte tra gli LLM (come Claude/GPT) e i tool reali. Ogni server MCP connette l'AI direttamente ad app, API e dati, trasformando i modelli da semplici chatbot ad agenti esecutivi.",
                docs_briefing: "Accesso diretto alle 'Source of Truth'. Qui trovi i link ufficiali alla documentazione, le tipologie di modelli supportati e i dettagli sull'hosting per i principali provider AI.",
                mcp_search_placeholder: "Cerca server MCP (es. file, slack, github)..."
            },
            en: {
                system_status: "SYSTEM_STATUS: ONLINE", view_label: "VIEW MODE", select_player: "SELECT PLAYER", search_placeholder: "ACCESS DATABASE: Search concepts...", init_title: "Initializing...", init_subtitle: "// AWAITING INPUT", loading: "LOADING INTELLIGENCE...", no_data: "NO DATA FOUND.", no_result: "NO RESULTS.", insight_label: "INSIGHT:", rate_limit: "⚠️ GITHUB RATE LIMIT REACHED.", author_note: "DEVELOPED BY:", guide_btn: "GUIDE",
                guide_title: "// SYSTEM MANUAL", guide_intro: "Welcome to AI THINGS. Navigate the AI ecosystem.", guide_mode_1: "<strong>KNOWLEDGE EXPLORER:</strong> Open Source libs, Frameworks & Guides.", guide_mode_2: "<strong>CORPORATE STACKS:</strong> Big Tech analysis.", guide_mode_3: "<strong>MCP PROTOCOL:</strong> The standard bridging LLMs to real-world data.", guide_mode_4: "<strong>OFFICIAL DOCS:</strong> Rapid access to official manuals and APIs.",
                mcp_briefing: "MCP (Model Context Protocol) is an open standard acting as a bridge between LLMs (like Claude/GPT) and real-world tools. Each MCP server connects AI directly to apps, APIs, and data — so agents don't just answer questions, they execute.",
                docs_briefing: "Direct access to the 'Source of Truth'. Here you find official documentation links, supported model types, and hosting details for major AI providers.",
                mcp_search_placeholder: "Search MCP Servers (e.g. file, slack, github)..."
            }
        };

        // --- MCP DATA (Fixed Links) ---
        const MCP_DATA = [
            { title: "File System MCP", link: "https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem", desc: {en: "Direct local file access (Read/Write). Automated file ops.", it: "Accesso diretto lettura/scrittura file locali. Operazioni file automatiche."} },
            { title: "GitHub MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github", desc: {en: "Code search, PRs & issue management inside dev pipeline.", it: "Ricerca codice, gestione PR e issue direttamente nel flusso dev."} },
            { title: "Slack MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack", desc: {en: "Read threads, send messages & trigger channel workflows.", it: "Lettura thread, invio messaggi e attivazione workflow nei canali."} },
            { title: "Google Maps MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps", desc: {en: "Access place data, routing & geolocation services.", it: "Accesso dati luoghi, routing e servizi di geolocalizzazione."} },
            { title: "PostgreSQL MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres", desc: {en: "Inspect DB schemas & run secure read-only analytics.", it: "Ispezione schemi DB e analisi dati read-only sicura."} },
            { title: "Google Drive MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive", desc: {en: "Search & read files/docs directly from Google Drive.", it: "Ricerca e lettura file/documenti direttamente da Google Drive."} },
            { title: "Sentry MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry", desc: {en: "Retrieve error logs & analyze stack traces.", it: "Recupero log errori e analisi stack trace."} },
            { title: "GitLab MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab", desc: {en: "Manage repositories, merge requests & pipelines.", it: "Gestione repository, merge request e pipeline."} },
            { title: "Memory MCP", link: "https://github.com/modelcontextprotocol/servers/tree/main/src/memory", desc: {en: "Graph-based persistent knowledge graph for agents.", it: "Grafo di conoscenza persistente per la memoria degli agenti."} },
            { title: "Brave Search MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search", desc: {en: "Privacy-first web & local search via Brave API.", it: "Ricerca web e locale privacy-first tramite API Brave."} },
            { title: "Puppeteer MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer", desc: {en: "Browser automation for scraping & UI testing.", it: "Automazione browser per scraping e test UI."} },
            { title: "Fetch MCP", link: "https://github.com/modelcontextprotocol/servers/tree/main/src/fetch", desc: {en: "Scrape web pages & convert content to markdown.", it: "Scraping pagine web e conversione contenuti in markdown."} },
            { title: "Redis MCP", link: "https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis", desc: {en: "Key-value store operations.", it: "Operazioni store chiave-valore."} }
        ];

        // --- DOCS DATA (STATIC) ---
        const DOCS_DATA = [
            { name: "OpenAI", link: "https://platform.openai.com/docs", linkText: "platform.openai.com", models: "Chat, Vision, Audio, Tools", hosting: "Cloud OpenAI (API), Azure OpenAI" },
            { name: "Google – Gemini API", link: "https://ai.google.dev/gemini-api/docs", linkText: "Google AI for Developers", models: "Multimodal native, JSON, realtime", hosting: "API standalone, Vertex AI" },
            { name: "Anthropic – Claude", link: "https://docs.anthropic.com/", linkText: "docs.anthropic.com", models: "Claude 3.5 Sonnet/Opus", hosting: "Console, AWS Bedrock, Azure" },
            { name: "Mistral AI", link: "https://docs.mistral.ai/", linkText: "docs.mistral.ai", models: "Mistral Large, Codestral", hosting: "La Plateforme, Azure" },
            { name: "Cohere", link: "https://docs.cohere.com", linkText: "docs.cohere.com", models: "Command R+, Embed, Rerank", hosting: "Cohere Cloud, AWS" },
            { name: "xAI – Grok", link: "https://docs.x.ai/", linkText: "docs.x.ai", models: "Grok 1.5, Vision", hosting: "Cloud xAI, Azure" },
            { name: "Meta – Llama API", link: "https://llama.developer.meta.com/docs/overview", linkText: "llama.developer.meta.com", models: "Llama 3 (8B, 70B, 400B)", hosting: "Managed API, AWS, Azure" },
            { name: "AWS – Bedrock", link: "https://docs.aws.amazon.com/bedrock/", linkText: "AWS Documentation", models: "Amazon Titan, Anthropic, Cohere", hosting: "Fully-managed AWS Service" },
            { name: "Microsoft – Azure AI", link: "https://learn.microsoft.com/azure/ai-foundry/", linkText: "Microsoft Learn", models: "OpenAI, Anthropic, Meta", hosting: "Azure Cloud (Managed endpoints)" },
            { name: "Google Cloud – Vertex AI", link: "https://docs.cloud.google.com/gemini/docs", linkText: "Google Cloud Docs", models: "Gemini, PaLM, Gemma", hosting: "Google Cloud managed platform" }
        ];

        // --- DATA ---
const REPO_THEMES = {
    core: {
        label: "CORE_INDEX",
        desc: { it: "Fondamenta AI", en: "AI Foundations" },
        briefing: {
            it: "Il nucleo duro: framework di deep learning, librerie per LLM, strumenti di data science e serving. Se vuoi costruire qualsiasi cosa in AI, prima o poi passi da qui.",
            en: "The hard core: deep learning frameworks, LLM libraries, data science tools and serving. If you want to build anything in AI, sooner or later you touch these."
        },
        items: [
            {
                id: "pytorch/pytorch",
                why: {
                    it: "Il motore matematico preferito dalla ricerca e da gran parte dell’industria: ti permette di sperimentare rapidamente nuove architetture e idee.",
                    en: "Research’s and industry’s favorite math engine: lets you rapidly experiment with new architectures and ideas."
                }
            },
            {
                id: "tensorflow/tensorflow",
                why: {
                    it: "La piattaforma storica di Google per ML su larga scala e produzione: ideale quando hai bisogno di un ecosistema maturo e ben integrato.",
                    en: "Google's historic platform for large-scale ML and production: ideal when you need a mature, well-integrated ecosystem."
                }
            },
            {
                id: "huggingface/transformers",
                why: {
                    it: "Il 'GitHub dei Modelli': migliaia di modelli pre-addestrati (NLP, visione, audio) da usare con poche righe di codice.",
                    en: "The 'GitHub of Models': thousands of pretrained models (NLP, vision, audio) ready to use with a few lines of code."
                }
            },
            {
                id: "langchain-ai/langchain",
                why: {
                    it: "Framework per connettere LLM a dati e servizi (PDF, DB, API) e costruire pipeline complesse di ragionamento e tool use.",
                    en: "Framework to connect LLMs to data and services (PDFs, DBs, APIs) and build complex reasoning and tool-use pipelines."
                }
            },
            {
                id: "run-llama/llama_index",
                why: {
                    it: "Specializzato nell’ingestione e indicizzazione dei dati per il RAG: ottimo per fare search intelligente su documenti e knowledge base.",
                    en: "Specialized in data ingestion and indexing for RAG: great for intelligent search over documents and knowledge bases."
                }
            },
            {
                id: "ray-project/ray",
                why: {
                    it: "Framework unificato per scalare job Python e workload AI su cluster: perfetto per training e inferenza distribuita senza impazzire con l’infrastruttura.",
                    en: "Unified framework to scale Python and AI workloads across clusters: great for distributed training and inference without drowning in infra."
                }
            },
            {
                id: "numpy/numpy",
                why: {
                    it: "La base di tutto: array numerici veloci, operazioni vettorializzate e algebra lineare. Senza di lui, il resto crolla.",
                    en: "The foundation of everything: fast numerical arrays, vectorized ops and linear algebra. Without it, the rest collapses."
                }
            },
            {
                id: "pandas-dev/pandas",
                why: {
                    it: "Il 'Excel programmabile': essenziale per pulire, trasformare e analizzare i dati prima di qualunque modello serio.",
                    en: "The 'programmable Excel': essential for cleaning, transforming and analysing data before any serious modeling."
                }
            },
            {
                id: "scikit-learn/scikit-learn",
                why: {
                    it: "Imbattibile per algoritmi classici (non deep): regressioni, classificazioni, clustering, preprocessing. Perfetto per baseline solide.",
                    en: "Unbeatable for classic (non-deep) algorithms: regression, classification, clustering, preprocessing. Perfect for solid baselines."
                }
            },
            {
                id: "tiangolo/fastapi",
                why: {
                    it: "Lo standard moderno per creare API veloci con Python: ideale per esporre i tuoi modelli AI in produzione.",
                    en: "The modern standard for building fast APIs in Python: ideal to expose your AI models in production."
                }
            },
            {
                id: "streamlit/streamlit",
                why: {
                    it: "Crea interfacce web per demo e tool AI in puro Python, senza HTML/CSS: perfetto per prototipare e condividere velocemente.",
                    en: "Create web UIs for AI demos and tools in pure Python, no HTML/CSS: perfect for fast prototyping and sharing."
                }
            }
        ]
    },

    databases: {
        label: "AI_DATABASES",
        desc: { it: "Memoria per AI", en: "AI Memory" },
        briefing: {
            it: "Database vettoriali, estensioni per Postgres e grafi di conoscenza: qui vive la memoria a lungo termine dei tuoi sistemi RAG e dei tuoi agenti.",
            en: "Vector databases, Postgres extensions and knowledge graphs: this is where long-term memory for your RAG systems and agents lives."
        },
        items: [
            {
                id: "milvus-io/milvus",
                why: {
                    it: "Database vettoriale cloud-native pensato per scalare a miliardi di vettori: adatto per applicazioni enterprise di ricerca semantica.",
                    en: "Cloud-native vector database designed to scale to billions of vectors: suitable for enterprise-grade semantic search."
                }
            },
            {
                id: "chroma-core/chroma",
                why: {
                    it: "Soluzione open-source 'AI-native', minimal e facile da integrare in applicazioni Python e prototipi RAG.",
                    en: "An 'AI-native' open-source solution, minimal and easy to integrate into Python apps and RAG prototypes."
                }
            },
            {
                id: "qdrant/qdrant",
                why: {
                    it: "Motore vettoriale in Rust, veloce ed efficiente, con supporto per filtri complessi e metadata: ottimo per search avanzata.",
                    en: "Rust-based vector engine, fast and efficient, with support for complex filters and metadata: great for advanced search."
                }
            },
            {
                id: "weaviate/weaviate",
                why: {
                    it: "DB vettoriale con moduli ML integrati e ricerca ibrida (testo + vettori): pensato per applicazioni semantiche end-to-end.",
                    en: "Vector DB with integrated ML modules and hybrid search (text + vectors): built for end-to-end semantic applications."
                }
            },
            {
                id: "facebookresearch/faiss",
                why: {
                    it: "Libreria fondamentale di Meta per la ricerca di similarità densa: usata sotto il cofano da molti motori vettoriali.",
                    en: "Meta’s fundamental library for dense similarity search: used under the hood by many vector engines."
                }
            },
            {
                id: "pgvector/pgvector",
                why: {
                    it: "Estensione per PostgreSQL che aggiunge supporto ai vettori: perfetta se vuoi aggiungere RAG senza cambiare database.",
                    en: "PostgreSQL extension that adds vector support: perfect if you want RAG without switching databases."
                }
            },
            {
                id: "lancedb/lancedb",
                why: {
                    it: "DB vettoriale serverless per dati multimodali (immagini, video, testo): ben integrato con workflow moderni e notebook.",
                    en: "Serverless vector DB for multimodal data (images, video, text): well integrated with modern workflows and notebooks."
                }
            },
            {
                id: "neo4j/neo4j",
                why: {
                    it: "Il database a grafo leader: cruciale per GraphRAG e sistemi che ragionano su relazioni tra concetti, entità ed eventi.",
                    en: "The leading graph database: crucial for GraphRAG and systems that reason over relationships between concepts, entities and events."
                }
            },
            {
                id: "redis/redis",
                why: {
                    it: "Key-value store ubiquo in produzione; oggi usato anche come vector store e cache per sistemi RAG e servizi AI real-time.",
                    en: "Ubiquitous production key-value store; now also used as a vector store and cache layer for RAG systems and real-time AI services."
                }
            }
        ]
    },

    learning: {
        label: "LEARNING",
        desc: { it: "Risorse Educative", en: "Educational Resources" },
        briefing: {
            it: "Libri, corsi e repository didattici per capire come funzionano davvero LLM, modelli di deep learning e ML classico. Qui costruisci la base mentale.",
            en: "Books, courses and educational repos to truly understand how LLMs, deep learning and classic ML work. This is where you build your mental foundation."
        },
        items: [
            {
                id: "rasbt/LLMs-from-scratch",
                why: {
                    it: "Libro/repo che ti guida a costruire un GPT-like da zero: perfetto per capire cosa succede sotto il cofano.",
                    en: "Book/repo that guides you to build a GPT-like model from scratch: perfect to understand what happens under the hood."
                }
            },
            {
                id: "huggingface/course",
                why: {
                    it: "Corso ufficiale gratuito di Hugging Face: copre Transformers, tokenizzazione, fine-tuning e deployment.",
                    en: "Hugging Face’s official free course: covers Transformers, tokenization, fine-tuning and deployment."
                }
            },
            {
                id: "karpathy/nanoGPT",
                why: {
                    it: "Codice minimale di Karpathy per addestrare un piccolo GPT: un capolavoro didattico per chi vuole imparare partendo dal codice.",
                    en: "Karpathy’s minimal code to train a small GPT: an educational gem if you want to learn by reading code."
                }
            },
            {
                id: "ageron/handson-ml3",
                why: {
                    it: "Notebook del libro 'Hands-On ML': coprono tutto, da Scikit-Learn a TensorFlow, con esempi pratici ben spiegati.",
                    en: "Notebooks from 'Hands-On ML': cover everything from Scikit-Learn to TensorFlow, with well-explained practical examples."
                }
            },
            {
                id: "fastai/fastai",
                why: {
                    it: "Approccio 'top-down' al deep learning: risultati velocemente, con API ad alto livello e spiegazioni progressive.",
                    en: "Top-down approach to deep learning: fast results with high-level APIs and progressive explanations."
                }
            },
            {
                id: "d2l-ai/d2l-en",
                why: {
                    it: "Dive into Deep Learning: libro interattivo completo con codice eseguibile e spiegazioni matematiche accessibili.",
                    en: "Dive into Deep Learning: complete interactive book with executable code and accessible math explanations."
                }
            },
            {
                id: "microsoft/ML-For-Beginners",
                why: {
                    it: "Curriculum di 12 settimane creato da Microsoft: ottimo per chi parte da zero e vuole una roadmap strutturata.",
                    en: "12-week curriculum by Microsoft: great for beginners who want a structured learning roadmap."
                }
            },
            {
                id: "openai/openai-cookbook",
                why: {
                    it: "Raccolta ufficiale di esempi pratici per costruire app reali con l’API OpenAI: dal prompt design al RAG, fino agli agenti.",
                    en: "Official collection of practical examples for building real apps with the OpenAI API: from prompt design and RAG to agents."
                }
            },
            {
                id: "meta-llama/llama-cookbook",
                why: {
                    it: "Ricettario ufficiale per inference, fine-tuning e casi d’uso end-to-end con la famiglia Llama: perfetto per lavorare seriamente con open weights.",
                    en: "Official cookbook for inference, fine-tuning and end-to-end use cases with the Llama family: perfect for serious work with open weights."
                }
            }
        ]
    },

    genai: {
        label: "GEN_AI",
        desc: { it: "Generazione Media", en: "Media Generation" },
        briefing: {
            it: "Strumenti per generare immagini, audio e testo, e per servire LLM in locale o in produzione. È la zona dove l’AI diventa creativa (e visual).",
            en: "Tools to generate images, audio and text, and to serve LLMs locally or in production. This is where AI gets creative (and visual)."
        },
        items: [
            {
                id: "AUTOMATIC1111/stable-diffusion-webui",
                why: {
                    it: "Interfaccia standard per usare Stable Diffusion: tantissime feature, estensioni e controlli per il prompting visivo.",
                    en: "Standard UI for Stable Diffusion: tons of features, extensions and controls for visual prompting."
                }
            },
            {
                id: "comfyanonymous/ComfyUI",
                why: {
                    it: "Interfaccia a nodi per Stable Diffusion: massima flessibilità per workflow complessi di generazione e post-processing.",
                    en: "Node-based UI for Stable Diffusion: maximum flexibility for complex generation and post-processing workflows."
                }
            },
            {
                id: "openai/whisper",
                why: {
                    it: "Uno dei migliori modelli open per speech-to-text: robusto, multilingua, ottimo per trascrizioni e pipeline audio.",
                    en: "One of the best open models for speech-to-text: robust, multilingual, great for transcription and audio pipelines."
                }
            },
            {
                id: "ollama/ollama",
                why: {
                    it: "Esegui Llama 3, Mistral e altri LLM sul tuo PC con un comando: perfetto per sperimentare modelli localmente.",
                    en: "Run Llama 3, Mistral and other LLMs on your machine with a single command: perfect for local experimentation."
                }
            },
            {
                id: "vllm-project/vllm",
                why: {
                    it: "Motore di inferenza ad altissimo throughput per LLM: pensato per servire molti utenti con latency bassa.",
                    en: "High-throughput inference engine for LLMs: designed to serve many users with low latency."
                }
            },
            {
                id: "lm-sys/FastChat",
                why: {
                    it: "Piattaforma aperta per addestrare, servire e valutare chatbot: include UI, backend e strumenti di benchmark.",
                    en: "Open platform to train, serve and evaluate chatbots: includes UI, backend and benchmarking tools."
                }
            },
            {
                id: "ggerganov/llama.cpp",
                why: {
                    it: "Il 'miracolo' che porta gli LLM su CPU e Apple Silicon: ideale per chi vuole modelli grandi su hardware non enterprise.",
                    en: "The 'miracle' bringing LLMs to CPU and Apple Silicon: ideal if you want big models on non-enterprise hardware."
                }
            },
            {
                id: "Stability-AI/generative-models",
                why: {
                    it: "Repo ufficiale per i modelli base di Stability AI (immagini, video, 3D): ottimo punto di accesso al loro ecosistema.",
                    en: "Official repo for Stability AI base models (images, video, 3D): a great entry point into their ecosystem."
                }
            },
            {
                id: "open-webui/open-webui",
                why: {
                    it: "Interfaccia web self-hosted per orchestrare LLM locali (es. Ollama) e remoti: chat, RAG, plugin e multi-modello in un unico posto.",
                    en: "Self-hosted web UI to orchestrate local (e.g. Ollama) and remote LLMs: chat, RAG, plugins and multi-model in a single place."
                }
            },
            {
                id: "janhq/jan",
                why: {
                    it: "App desktop open che porta l’esperienza tipo ChatGPT su modelli locali e cloud, con un’unica interfaccia pulita.",
                    en: "Open desktop app bringing a ChatGPT-like experience to local and cloud models through a single clean interface."
                }
            }
        ]
    },

    agentic: {
        label: "AGENTIC_AI",
        desc: { it: "Agenti Autonomi", en: "Autonomous Agents" },
        briefing: {
            it: "Framework e tool per costruire agenti che non si limitano a rispondere, ma pianificano, chiamano tool, leggono e scrivono file, orchestrano workflow.",
            en: "Frameworks and tools to build agents that don’t just answer, but plan, call tools, read/write files and orchestrate workflows."
        },
        items: [
            {
                id: "langchain-ai/langchain",
                why: {
                    it: "Framework storico per orchestrare LLM, memorie e tool: ottimo per prototipi veloci e per capire i pattern di base degli agenti.",
                    en: "Historic framework to orchestrate LLMs, memory and tools: great for fast prototyping and learning basic agent patterns."
                }
            },
            {
                id: "langchain-ai/langgraph",
                why: {
                    it: "Evoluzione di LangChain per creare agenti stateful, ciclici e robusti: pensato per applicazioni più complesse e affidabili.",
                    en: "LangChain’s evolution for building stateful, cyclic and robust agents: aimed at more complex and reliable applications."
                }
            },
            {
                id: "microsoft/autogen",
                why: {
                    it: "Crea team di agenti che conversano tra loro per risolvere task: perfetto per scenari multi-ruolo (planner, coder, reviewer).",
                    en: "Create teams of agents that talk to each other to solve tasks: perfect for multi-role scenarios (planner, coder, reviewer)."
                }
            },
            {
                id: "crewAIInc/crewAI",
                why: {
                    it: "Orchestra agenti con ruoli specifici (es. Ricercatore, Scrittore, Strategist) e flussi di lavoro coordinati.",
                    en: "Orchestrates agents with specific roles (e.g., Researcher, Writer, Strategist) and coordinated workflows."
                }
            },
            {
                id: "Significant-Gravitas/AutoGPT",
                why: {
                    it: "Uno dei primi agenti autonomi 'goal-driven': gli dai un obiettivo e lui prova a decomporlo in passi e azioni.",
                    en: "One of the first 'goal-driven' autonomous agents: you give it a goal and it tries to decompose it into steps and actions."
                }
            },
            {
                id: "OpenInterpreter/open-interpreter",
                why: {
                    it: "Permette a un LLM di eseguire vero codice sul tuo computer (shell, Python, ecc.): ponte diretto tra modello e ambiente locale.",
                    en: "Lets an LLM execute real code on your machine (shell, Python, etc.): a direct bridge between model and local environment."
                }
            },
            {
                id: "microsoft/semantic-kernel",
                why: {
                    it: "SDK leggero per integrare LLM in codice 'tradizionale' (C#, Python): perfetto per agenti che vivono dentro servizi esistenti.",
                    en: "Lightweight SDK to integrate LLMs into 'traditional' code (C#, Python): perfect for agents living inside existing services."
                }
            },
            {
                id: "deepset-ai/haystack",
                why: {
                    it: "Framework end-to-end per RAG e sistemi agentici production-ready: pipeline, integrazioni, eval e deployment in un unico stack.",
                    en: "End-to-end framework for RAG and production-ready agentic systems: pipelines, integrations, eval and deployment in a single stack."
                }
            }
        ]
    },

    ml: {
        label: "MACHINE_LEARNING",
        desc: { it: "ML Classico", en: "Classic ML" },
        briefing: {
            it: "Algoritmi classici, ensemble e calcolo numerico: tutto ciò che esisteva prima dell’ondata LLM e che continua a risolvere un sacco di problemi reali.",
            en: "Classic algorithms, ensembles and numerical computing: everything that existed before the LLM wave and still solves a ton of real problems."
        },
        items: [
            {
                id: "pytorch/pytorch",
                why: {
                    it: "Framework ormai dominante anche oltre il deep puro: usato come base per molti progetti di ricerca e produzione.",
                    en: "Dominant framework beyond pure deep learning: used as a base for many research and production projects."
                }
            },
            {
                id: "tensorflow/tensorflow",
                why: {
                    it: "Standard di fatto per molte pipeline di produzione storiche: ancora molto presente in ecosistemi enterprise.",
                    en: "De facto standard for many legacy production pipelines: still very present in enterprise ecosystems."
                }
            },
            {
                id: "scikit-learn/scikit-learn",
                why: {
                    it: "Strumenti semplici ed efficienti per analisi dati e ML classico: la libreria da conoscere se lavori con tabellari e feature engineering.",
                    en: "Simple and efficient tools for data mining and classic ML: the library to know if you work with tabular data and feature engineering."
                }
            },
            {
                id: "dmlc/xgboost",
                why: {
                    it: "Il re delle competizioni su dati tabellari: gradient boosting estremamente performante e ben rodato.",
                    en: "The king of tabular data competitions: extremely strong and battle-tested gradient boosting."
                }
            },
            {
                id: "microsoft/LightGBM",
                why: {
                    it: "Gradient boosting veloce ed efficiente con ottima gestione di grandi dataset: alternativa spesso più leggera rispetto ad altri.",
                    en: "Fast, efficient gradient boosting with great handling of large datasets: often a lighter alternative to others."
                }
            },
            {
                id: "catboost/catboost",
                why: {
                    it: "Gradient boosting pensato per gestire in modo eccellente le feature categoriali: spesso top su problemi tabellari reali.",
                    en: "Gradient boosting library that handles categorical features extremely well: often top-tier on real-world tabular problems."
                }
            },
            {
                id: "numpy/numpy",
                why: {
                    it: "Base del calcolo scientifico in Python: tutto il resto (ML, DL, statistica) si appoggia sopra i suoi array.",
                    en: "Base of scientific computing in Python: everything else (ML, DL, stats) sits on top of its arrays."
                }
            },
            {
                id: "pandas-dev/pandas",
                why: {
                    it: "Strumento potente per analisi e manipolazione dati: essenziale per preparare feature e dataset puliti.",
                    en: "Powerful tool for data analysis and manipulation: essential for preparing clean features and datasets."
                }
            },
            {
                id: "google/jax",
                why: {
                    it: "Autograd e XLA per calcolo ad alte prestazioni: ponte naturale tra numerica classica e sperimentazione deep moderna.",
                    en: "Autograd and XLA for high-performance computation: a natural bridge between classic numerics and modern deep experiments."
                }
            }
        ]
    },

    opensource: {
        label: "OPEN_SOURCE_AI",
        desc: { it: "Hub & Modelli", en: "Hub & Models" },
        briefing: {
            it: "Piattaforme, modelli open-weight e progetti comunitari: qui si muove l’AI aperta, dove puoi ispezionare, forchettare e costruire sopra.",
            en: "Platforms, open-weight models and community projects: this is where open AI lives, where you can inspect, fork and build on top."
        },
        items: [
            {
                id: "huggingface/transformers",
                why: {
                    it: "Migliaia di modelli pre-addestrati pronti all’uso: l’hub più importante per chi lavora con modelli open.",
                    en: "Thousands of pretrained models ready to use: the most important hub if you work with open models."
                }
            },
            {
                id: "huggingface/diffusers",
                why: {
                    it: "Modelli di diffusione per generazione di immagini, audio e altro: lo standard de facto per sperimentare con diffusion models.",
                    en: "Diffusion models for image, audio and more: the de facto standard for experimenting with diffusion models."
                }
            },
            {
                id: "huggingface/peft",
                why: {
                    it: "Fine-tuning efficiente (LoRA & co.) per modelli grandi: ti permette di adattare LLM con poca memoria e pochi dati.",
                    en: "Efficient fine-tuning (LoRA & co.) for large models: lets you adapt LLMs with limited memory and data."
                }
            },
            {
                id: "facebookresearch/llama",
                why: {
                    it: "La famiglia di modelli che ha democratizzato gli LLM potenti in versione open-weight.",
                    en: "The model family that democratized powerful LLMs in open-weight form."
                }
            },
            {
                id: "meta-llama/llama3",
                why: {
                    it: "Release ufficiale dei pesi Llama 3: modelli open-weight moderni, base di tanti progetti LLM open in produzione.",
                    en: "Official Llama 3 weights release: modern open-weight models that power many real-world open LLM projects."
                }
            },
            {
                id: "mistralai/mistral-src",
                why: {
                    it: "Modelli efficienti e performanti open-weight: spesso ai primi posti per rapporto qualità/risorse.",
                    en: "Efficient, high-performance open-weight models: often leading in quality-to-resources ratio."
                }
            },
            {
                id: "EleutherAI/gpt-neox",
                why: {
                    it: "Libreria per addestrare modelli Transformer di grandi dimensioni su GPU: fondamentale nella storia degli LLM open.",
                    en: "Library to train large Transformer models on GPUs: a key piece in the history of open LLMs."
                }
            },
            {
                id: "LAION-AI/Open-Assistant",
                why: {
                    it: "Assistente conversazionale open source guidato dalla community: dimostra cosa si può fare con dati e collaborazione aperta.",
                    en: "Community-driven open-source conversational assistant: shows what’s possible with open data and collaboration."
                }
            }
        ]
    }
};

        const TITAN_THEMES = {
    meta: {
        label: "META (FAIR)",
        desc: {
            it: "Open Weights, Vision & Retrieval",
            en: "Open Weights, Vision & Retrieval"
        },
        briefing: {
            it: "Il team FAIR di Meta è uno dei motori principali dell'AI open-weight: Llama per il linguaggio, SAM e Detectron2 per la visione, FAISS per la ricerca vettoriale. Qui trovi i mattoni fondamentali per costruire sistemi completi (LLM + Vision + Retrieval).",
            en: "Meta’s FAIR team is one of the main drivers of open-weight AI: Llama for language, SAM and Detectron2 for vision, FAISS for vector search. This is the toolbox for building full systems (LLM + Vision + Retrieval)."
        },
        items: [
            {
                id: "facebookresearch/llama",
                why: {
                    it: "La famiglia di modelli open più influente degli ultimi anni: ha sbloccato ecosistemi interi (fine-tuning, inference, strumenti, UI) su hardware accessibile.",
                    en: "The most influential open model family in recent years: it unlocked entire ecosystems (fine-tuning, inference, tools, UIs) on accessible hardware."
                }
            },
            {
                id: "pytorch/pytorch",
                why: {
                    it: "Il framework preferito dalla ricerca e da gran parte dell’industria: se leggi un paper moderno, è molto probabile che l’implementazione sia in PyTorch.",
                    en: "The framework of choice for research and a big part of industry: if you read a modern paper, chances are the reference implementation is in PyTorch."
                }
            },
            {
                id: "facebookresearch/segment-anything",
                why: {
                    it: "Segment Anything Model (SAM): segmentazione immagini universale, pensata per funzionare out-of-the-box su una grande varietà di scenari.",
                    en: "Segment Anything Model (SAM): universal image segmentation, designed to work out-of-the-box in a wide variety of scenarios."
                }
            },
            {
                id: "facebookresearch/detectron2",
                why: {
                    it: "Piattaforma next-gen per object detection e instance segmentation: ancora un riferimento per sistemi di visione classici e ibridi.",
                    en: "Next-gen platform for object detection and instance segmentation: still a reference point for classic and hybrid vision systems."
                }
            },
            {
                id: "facebookresearch/faiss",
                why: {
                    it: "Libreria chiave per la ricerca di similarità su grandi collezioni di vettori: alla base di tanti motori di RAG e recommendation.",
                    en: "Key library for similarity search on large vector collections: underpins many RAG engines and recommendation systems."
                }
            },
            {
                id: "facebookresearch/dinov2",
                why: {
                    it: "Vision transformer autosupervisionato che fornisce embedding robusti per task downstream (classification, retrieval, segmentation).",
                    en: "Self-supervised vision transformer providing robust embeddings for downstream tasks (classification, retrieval, segmentation)."
                }
            },
            {
                id: "facebookresearch/fastText",
                why: {
                    it: "Classificazione e rappresentazione del testo veloce e leggera: ideale per baseline solide e sistemi in cui latenza e risorse contano.",
                    en: "Fast and lightweight text classification and representation: ideal for solid baselines and systems where latency and resources matter."
                }
            }
        ]
    },

    microsoft: {
        label: "MICROSOFT",
        desc: {
            it: "Enterprise, Agents & Knowledge",
            en: "Enterprise, Agents & Knowledge"
        },
        briefing: {
            it: "Microsoft spinge forte su agenti multi-LLM, integrazione con ecosistemi enterprise (Azure, M365) e gestione della conoscenza (GraphRAG). Qui trovi gli strumenti per costruire sistemi agentici robusti dentro contesti aziendali reali.",
            en: "Microsoft is pushing on multi-LLM agents, enterprise integration (Azure, M365) and knowledge-centric systems (GraphRAG). This is the toolbox for building robust agentic systems inside real organizations."
        },
        items: [
            {
                id: "microsoft/autogen",
                why: {
                    it: "Framework per creare team di agenti che collaborano tra loro: utile per orchestrare ruoli diversi (planner, coder, critico) su task complessi.",
                    en: "Framework for creating teams of collaborating agents: useful to orchestrate different roles (planner, coder, critic) on complex tasks."
                }
            },
            {
                id: "microsoft/DeepSpeed",
                why: {
                    it: "Stack di ottimizzazione per addestrare modelli di grandi dimensioni in modo efficiente (parallelismo, memory saving, throughput elevato).",
                    en: "Optimization stack for training large models efficiently (parallelism, memory savings, high throughput)."
                }
            },
            {
                id: "microsoft/semantic-kernel",
                why: {
                    it: "SDK leggero per integrare LLM in app esistenti (C#, Python, Java, ecc.): perfetto per portare AI in sistemi enterprise già in produzione.",
                    en: "Lightweight SDK to integrate LLMs into existing apps (C#, Python, Java, etc.): ideal to bring AI into existing enterprise systems."
                }
            },
            {
                id: "microsoft/graphrag",
                why: {
                    it: "Approccio RAG basato su knowledge graph: permette di strutturare, navigare e interrogare la conoscenza in modo più robusto del semplice “chunking”.",
                    en: "Graph-based RAG approach: lets you structure, navigate and query knowledge more robustly than naïve chunking."
                }
            },
            {
                id: "microsoft/guidance",
                why: {
                    it: "Linguaggio dichiarativo per controllare il comportamento degli LLM (template, vincoli, strutture). Utile quando serve output molto deterministico.",
                    en: "Declarative language to control LLM behavior (templates, constraints, structures). Useful when you need highly deterministic outputs."
                }
            },
            {
                id: "microsoft/playwright",
                why: {
                    it: "Automazione browser moderna e affidabile: fondamentale per agenti che devono interagire con web app reali end-to-end.",
                    en: "Modern, reliable browser automation: essential for agents that must interact with real web apps end-to-end."
                }
            },
            {
                id: "microsoft/LIDA",
                why: {
                    it: "Strumento per generare visualizzazioni dati e insight guidati dagli LLM: collega direttamente analisi e storytelling visivo.",
                    en: "Tool for generating data visualizations and insights with LLMs: directly connects analysis and visual storytelling."
                }
            }
        ]
    },

    google: {
        label: "GOOGLE",
        desc: {
            it: "Research & Agents",
            en: "Research & Agents"
        },
        briefing: {
            it: "Pionieri della ricerca AI (da BERT a JAX), oggi sempre più focalizzati su agenti e workflow produttivi con Gemini e ADK. Qui ci sono gli strumenti chiave per passare dalla ricerca al prodotto.",
            en: "AI research pioneers (from BERT to JAX), now heavily focused on agents and production workflows with Gemini and ADK. These are the key tools to move from research to product."
        },
        items: [
            {
                id: "google/adk-python",
                why: {
                    it: "Agent Development Kit: il framework ufficiale per progettare, orchestrare e mettere in produzione agenti avanzati (ottimizzato per Gemini, ma model-agnostic).",
                    en: "Agent Development Kit: the official framework to design, orchestrate and deploy advanced agents (optimized for Gemini, but model-agnostic)."
                }
            },
            {
                id: "google-gemini/gemini-cli",
                why: {
                    it: "Un agente Gemini pronto nel terminale: esempio concreto di utilizzo quotidiano per coding, refactor e debugging del codice.",
                    en: "A Gemini-powered agent in your terminal: concrete everyday usage example for coding, refactors and debugging."
                }
            },
            {
                id: "GoogleCloudPlatform/agent-starter-pack",
                why: {
                    it: "Starter pack per agenti in produzione su Google Cloud: infrastruttura, CI/CD, logging e sicurezza già impostati secondo best practice.",
                    en: "Starter pack for production-grade agents on Google Cloud: infra, CI/CD, logging and security wired in following best practices."
                }
            },
            {
                id: "google-deepmind/gemma",
                why: {
                    it: "Libreria ufficiale Gemma: modelli LLM open-weight di Google pensati per essere usati e fine-tunati in applicazioni reali, non solo per benchmark.",
                    en: "Official Gemma library: Google’s open-weight LLMs designed to be used and fine-tuned in real applications, not just for benchmarks."
                }
            },
            {
                id: "google/gemma.cpp",
                why: {
                    it: "Motore di inferenza C++ leggero per Gemma, in stile llama.cpp: ideale per portare LLM open su laptop e dispositivi edge.",
                    en: "Lightweight C++ inference engine for Gemma, llama.cpp-style: ideal for running open LLMs on laptops and edge devices."
                }
            },
            {
                id: "google/jax",
                why: {
                    it: "Il laboratorio numerico di Google: autograd + XLA per ricerca e training ad alte prestazioni su TPU e GPU.",
                    en: "Google’s numerical lab: autograd + XLA for high-performance research and training on TPUs and GPUs."
                }
            },
            {
                id: "google-ai-edge/ai-edge-apis",
                why: {
                    it: "SDK e API per portare GenAI e ML direttamente in app mobile/web con esecuzione on-device: perfetto per esperienze low-latency.",
                    en: "SDKs and APIs to bring GenAI and ML directly into mobile/web apps with on-device execution: ideal for low-latency experiences."
                }
            }
        ]
    },

    openai: {
        label: "OPENAI",
        desc: {
            it: "Generative Models & Tooling",
            en: "Generative Models & Tooling"
        },
        briefing: {
            it: "Definiscono (o spostano) regolarmente lo stato dell’arte su linguaggio, multimodale e strumenti di produzione. Qui trovi i pezzi principali per lavorare con l’ecosistema OpenAI oltre la semplice chiamata API.",
            en: "They regularly define (or push) the state of the art in language, multimodal and production tooling. These are the main pieces to work with the OpenAI ecosystem beyond a simple API call."
        },
        items: [
            {
                id: "openai/whisper",
                why: {
                    it: "Modello di speech-to-text robusto, multilingua, usatissimo per trascrizioni, subtitling e analisi conversazionali.",
                    en: "Robust, multilingual speech-to-text model widely used for transcription, subtitling and conversational analytics."
                }
            },
            {
                id: "openai/tiktoken",
                why: {
                    it: "Tokenizzatore BPE veloce e ottimizzato per i modelli OpenAI: fondamentale per stimare costi, lunghezze di contesto e controllare l’input.",
                    en: "Fast BPE tokenizer optimized for OpenAI models: essential to estimate cost, context length and control the input."
                }
            },
            {
                id: "openai/clip",
                why: {
                    it: "Modello che collega testo e immagini in uno spazio comune: base concettuale per tante applicazioni vision-language moderne.",
                    en: "Model that connects text and images in a shared space: conceptual base for many modern vision-language applications."
                }
            },
            {
                id: "openai/evals",
                why: {
                    it: "Framework per valutare LLM in modo sistematico (task custom, dataset, metriche): utile quando devi davvero misurare qualità, non solo “sensazioni”.",
                    en: "Framework to systematically evaluate LLMs (custom tasks, datasets, metrics): useful when you need real measurement, not just vibes."
                }
            },
            {
                id: "openai/shap-e",
                why: {
                    it: "Modello per generare oggetti 3D a partire da testo o immagini: ponte tra GenAI e pipeline 3D/CAD.",
                    en: "Model to generate 3D objects from text or images: bridge between GenAI and 3D/CAD pipelines."
                }
            },
            {
                id: "openai/point-e",
                why: {
                    it: "Generazione di nuvole di punti 3D: interessante per prototipi rapidi nel mondo 3D e robotics.",
                    en: "3D point cloud generation: useful for quick prototyping in 3D and robotics contexts."
                }
            },
            {
                id: "openai/openai-python",
                why: {
                    it: "Libreria Python ufficiale: il modo più diretto e stabile per integrare le API OpenAI in backend, script e pipeline.",
                    en: "Official Python library: the most direct and stable way to integrate OpenAI APIs into backends, scripts and pipelines."
                }
            }
        ]
    },

    huggingface: {
        label: "HUGGING FACE",
        desc: {
            it: "The AI Hub & Ecosystem",
            en: "The AI Hub & Ecosystem"
        },
        briefing: {
            it: "La casa dell’AI open: modelli, dataset, spazio di deploy e librerie per training, fine-tuning e serving. Qui trovi gli strumenti che tengono in piedi mezza AI open source moderna.",
            en: "Home of open AI: models, datasets, deployment space and libraries for training, fine-tuning and serving. These are the tools that power half of modern open-source AI."
        },
        items: [
            {
                id: "huggingface/transformers",
                why: {
                    it: "Libreria di riferimento per usare modelli Transformer (NLP, visione, audio) con poche righe di codice: lo standard de facto.",
                    en: "Reference library to use Transformer models (NLP, vision, audio) with just a few lines of code: the de facto standard."
                }
            },
            {
                id: "huggingface/diffusers",
                why: {
                    it: "Toolkit per modelli di diffusione (immagini, audio, video): il modo più semplice per sperimentare con generazione moderna.",
                    en: "Toolkit for diffusion models (images, audio, video): the easiest way to experiment with modern generative models."
                }
            },
            {
                id: "huggingface/peft",
                why: {
                    it: "Parameter-Efficient Fine-Tuning: permette di adattare LLM e modelli grossi con poche risorse e senza toccare tutti i pesi.",
                    en: "Parameter-Efficient Fine-Tuning: lets you adapt LLMs and large models with limited resources, without touching all weights."
                }
            },
            {
                id: "huggingface/datasets",
                why: {
                    it: "Libreria per scaricare, preparare e condividere dataset ML in modo standardizzato: fondamentale per esperimenti riproducibili.",
                    en: "Library to download, prepare and share ML datasets in a standardized way: essential for reproducible experiments."
                }
            },
            {
                id: "huggingface/accelerate",
                why: {
                    it: "Astrazione per training distribuito e multi-device: rende più semplice scalare senza dover riscrivere mezzo training loop.",
                    en: "Abstraction for distributed and multi-device training: simplifies scaling without rewriting half your training loop."
                }
            },
            {
                id: "huggingface/tokenizers",
                why: {
                    it: "Tokenizzatori veloci scritti in Rust con binding Python: indispensabili quando il preprocessing diventa un collo di bottiglia.",
                    en: "Fast tokenizers written in Rust with Python bindings: indispensable when preprocessing becomes a bottleneck."
                }
            },
            {
                id: "huggingface/text-generation-inference",
                why: {
                    it: "Toolkit di serving ottimizzato per LLM (quantizzazione, batching, multi-GPU): pensato per portare modelli open in produzione.",
                    en: "Optimized serving toolkit for LLMs (quantization, batching, multi-GPU): designed to bring open models into production."
                }
            }
        ]
    },

    nvidia: {
        label: "NVIDIA",
        desc: {
            it: "Compute, Inference & Optimization",
            en: "Compute, Inference & Optimization"
        },
        briefing: {
            it: "Il layer hardware e runtime sotto gran parte dell’AI moderna. Da TensorRT a NeMo, questi strumenti sono ciò che ti permette di sfruttare davvero le GPU oltre il semplice training naïf.",
            en: "The hardware and runtime layer under most modern AI. From TensorRT to NeMo, these tools let you actually leverage GPUs beyond naïve training."
        },
        items: [
            {
                id: "NVIDIA/NeMo",
                why: {
                    it: "Toolkit per costruire, addestrare e deployare modelli conversazionali e multimodali di grandi dimensioni, con pipeline già strutturate.",
                    en: "Toolkit to build, train and deploy large conversational and multimodal models, with structured pipelines."
                }
            },
            {
                id: "NVIDIA/TensorRT",
                why: {
                    it: "Piattaforma di ottimizzazione e inferenza ad alte prestazioni per modelli deep: essenziale quando la latenza va abbassata al minimo.",
                    en: "High-performance optimization and inference platform for deep models: essential when you need to squeeze latency down."
                }
            },
            {
                id: "NVIDIA/dali",
                why: {
                    it: "Libreria per data loading e preprocessing accelerato su GPU: evita che il caricamento dati diventi il vero collo di bottiglia.",
                    en: "Library for data loading and preprocessing accelerated on GPU: prevents data loading from becoming the real bottleneck."
                }
            },
            {
                id: "NVIDIA/cuda-samples",
                why: {
                    it: "Collezione di esempi ufficiali per CUDA: ottimo punto di partenza per capire come sfruttare davvero le GPU a basso livello.",
                    en: "Collection of official CUDA examples: great starting point to understand how to really use GPUs at a low level."
                }
            },
            {
                id: "NVIDIA/Megatron-LM",
                why: {
                    it: "Framework per addestrare LLM enormi con parallelismo avanzato (tensor, pipeline, data parallel): riferimento per training su scala massiva.",
                    en: "Framework for training huge LLMs with advanced parallelism (tensor, pipeline, data parallel): a reference for training at massive scale."
                }
            }
        ]
    },

    mistral: {
        label: "CHALLENGERS",
        desc: {
            it: "New Powers & Open Models",
            en: "New Powers & Open Models"
        },
        briefing: {
            it: "Nuovi attori che si muovono veloci: Mistral, xAI, Cohere, Stability. Qui ci sono modelli e tool che spesso arrivano per primi su efficienza, qualità open-weight e sperimentazione.",
            en: "New fast-moving players: Mistral, xAI, Cohere, Stability. These models and tools often lead on efficiency, open-weight quality and experimentation."
        },
        items: [
            {
                id: "mistralai/mistral-src",
                why: {
                    it: "Codice di riferimento dei modelli Mistral: utile per capire come sono strutturati e come integrarli a basso livello.",
                    en: "Reference code for Mistral models: useful to understand their structure and integrate them at a low level."
                }
            },
            {
                id: "mistralai/mistral-inference",
                why: {
                    it: "Libreria di inferenza Python per i modelli Mistral: pensata per portare rapidamente i loro LLM in produzione.",
                    en: "Python inference library for Mistral models: designed to quickly bring their LLMs into production."
                }
            },
            {
                id: "xai-org/grok-1",
                why: {
                    it: "Modello open-weight di xAI: focalizzato su reasoning e contesto ampio, interessante per chi vuole esplorare alternative ai soliti noti.",
                    en: "xAI’s open-weight model: focused on reasoning and large context, interesting if you want alternatives to the usual suspects."
                }
            },
            {
                id: "cohere-ai/cohere-python",
                why: {
                    it: "SDK Python ufficiale per i modelli Cohere (Command, Embed, Rerank): utile per costruire pipeline di search e applicazioni enterprise.",
                    en: "Official Python SDK for Cohere models (Command, Embed, Rerank): useful for building search pipelines and enterprise applications."
                }
            },
            {
                id: "Stability-AI/stablediffusion",
                why: {
                    it: "Implementazione storica di Stable Diffusion: la base da cui è esplosa la generazione di immagini open source.",
                    en: "Historical Stable Diffusion implementation: the base from which open-source image generation exploded."
                }
            }
        ]
    },

    anthropic: {
        label: "ANTHROPIC",
        desc: {
            it: "Safety, Claude & Agents",
            en: "Safety, Claude & Agents"
        },
        briefing: {
            it: "Creatori di Claude, molto focalizzati su sicurezza, affidabilità e tool agentici. Qui trovi sia le librerie per usare i modelli, sia il materiale per capire come progettarli e valutarli in modo responsabile.",
            en: "Creators of Claude, heavily focused on safety, reliability and agentic tools. Here you find both the libraries to use the models and the material to design and evaluate them responsibly."
        },
        items: [
            {
                id: "anthropics/claude-code",
                why: {
                    it: "Agente di coding autonomo da terminale: mostra come un modello tipo Claude può comprendere, navigare e modificare codebase complesse in modo iterativo.",
                    en: "Autonomous coding agent in your terminal: shows how a model like Claude can understand, navigate and modify complex codebases iteratively."
                }
            },
            {
                id: "anthropics/skills",
                why: {
                    it: "Raccolta ufficiale di tool per agenti Claude (API, servizi, integrazioni): ottimo punto di partenza per costruire agenti utili nella pratica.",
                    en: "Official collection of tools for Claude agents (APIs, services, integrations): great starting point to build practically useful agents."
                }
            },
            {
                id: "anthropics/prompt-eng-interactive-tutorial",
                why: {
                    it: "Tutorial interattivo di prompt engineering: ti porta, passo dopo passo, da prompt naïf a pattern più robusti e riutilizzabili.",
                    en: "Interactive prompt engineering tutorial: walks you step-by-step from naïve prompts to more robust and reusable patterns."
                }
            },
            {
                id: "anthropics/anthropic-sdk-python",
                why: {
                    it: "SDK Python ufficiale per integrare Claude (3.5 e successivi) in backend, script e pipeline dati.",
                    en: "Official Python SDK to integrate Claude (3.5 and later) into backends, scripts and data pipelines."
                }
            },
            {
                id: "anthropics/anthropic-cookbook",
                why: {
                    it: "Repository essenziale con esempi avanzati (RAG, citazioni con fonti, Vision, tool use): perfetto come “laboratorio” per progetti seri.",
                    en: "Essential repo with advanced examples (RAG, cited answers, Vision, tool use): perfect as a 'lab' for real projects."
                }
            },
            {
                id: "anthropics/courses",
                why: {
                    it: "Materiale educativo su sicurezza, allineamento e best practice di utilizzo: utile per chi vuole andare oltre la semplice integrazione tecnica.",
                    en: "Educational material on safety, alignment and usage best practices: useful if you want to go beyond plain technical integration."
                }
            }
        ]
    }
};


        // --- DOM ---
        const dom = {
            viewSelector: document.getElementById('view-selector'), viewExplorer: document.getElementById('view-explorer'), viewTitans: document.getElementById('view-titans'), viewMcp: document.getElementById('view-mcp'), viewDocs: document.getElementById('view-docs'),
            searchInput: document.getElementById('search-input'), executeButton: document.getElementById('execute-query-button'),
            expButtonsContainer: document.getElementById('category-buttons'), titansButtonsContainer: document.getElementById('titans-buttons'),
            resultsContainer: document.getElementById('results-container'), titansContainer: document.getElementById('titans-container'), mcpContainer: document.getElementById('mcp-container'), docsContainer: document.getElementById('docs-container'),
            resultsTitle: document.getElementById('results-title'), resultsSubtitle: document.getElementById('results-subtitle'),
            explorerBriefing: document.getElementById('explorer-briefing'), explorerBriefingText: document.getElementById('explorer-briefing-text'),
            titanBriefing: document.getElementById('titan-briefing'), titanBriefingTitle: document.getElementById('titan-briefing-title'), titanBriefingText: document.getElementById('titan-briefing-text'),
            mcpBriefingText: document.getElementById('mcp-briefing-text'), docsBriefingText: document.getElementById('docs-briefing-text'),
            titanHeaderName: document.getElementById('titan-header-name'), titanLogo: document.getElementById('titan-logo-placeholder'),
            spinnerExp: document.getElementById('loading-spinner-exp'), spinnerTitans: document.getElementById('loading-spinner-titans'),
            apiStatusDot: document.getElementById('api-status-dot'), langEn: document.getElementById('lang-en'), langIt: document.getElementById('lang-it'),
            modalGuide: document.getElementById('guide-modal'), btnOpenGuide: document.getElementById('btn-open-guide'), btnCloseGuide: document.getElementById('btn-close-guide')
        };

        // --- LANGUAGE LOGIC ---
        function detectLanguage() { const userLang = navigator.language || navigator.userLanguage; setLanguage(userLang.startsWith('it') ? 'it' : 'en'); }
        
        function setLanguage(lang) {
            currentLang = lang;
            dom.langEn.classList.toggle('active', lang === 'en'); dom.langIt.classList.toggle('active', lang === 'it');
            const texts = I18N[lang];
            
            document.querySelector('[data-i18n="system_status"]').textContent = texts.system_status;
            document.querySelector('[data-i18n="view_label"]').textContent = texts.view_label;
            document.querySelector('[data-i18n="select_player"]').textContent = texts.select_player;
            document.querySelector('[data-i18n="loading"]').textContent = texts.loading;
            document.querySelector('[data-i18n="author_note"]').textContent = texts.author_note;
            document.querySelector('[data-i18n="guide_btn"]').textContent = texts.guide_btn;
            
            document.querySelector('[data-i18n="guide_title"]').textContent = texts.guide_title;
            document.querySelector('[data-i18n="guide_intro"]').textContent = texts.guide_intro;
            document.querySelector('[data-i18n="guide_mode_1"]').innerHTML = texts.guide_mode_1;
            document.querySelector('[data-i18n="guide_mode_2"]').innerHTML = texts.guide_mode_2;
            document.querySelector('[data-i18n="guide_mode_3"]').innerHTML = texts.guide_mode_3;
            document.querySelector('[data-i18n="guide_mode_4"]').innerHTML = texts.guide_mode_4;
            
            if(dom.mcpBriefingText) dom.mcpBriefingText.textContent = texts.mcp_briefing;
            if(dom.docsBriefingText) dom.docsBriefingText.textContent = texts.docs_briefing;

            dom.searchInput.placeholder = texts.search_placeholder;

            const activeCategory = document.querySelector('.btn-category.active');
            if (activeCategory) {
                const key = activeCategory.dataset.key;
                if (!dom.viewExplorer.classList.contains('hidden')) updateExplorerContent(key);
                else if (!dom.viewTitans.classList.contains('hidden')) updateTitanContent(key);
            }
            
            if (!dom.viewMcp.classList.contains('hidden')) renderMCPGrid();
            if (!dom.viewDocs.classList.contains('hidden')) renderDocsGrid();
            
            updateSearchPlaceholder();
        }

        function updateSearchPlaceholder() {
             if (!dom.viewMcp.classList.contains('hidden')) {
                 dom.searchInput.placeholder = I18N[currentLang].mcp_search_placeholder;
             } else {
                 dom.searchInput.placeholder = I18N[currentLang].search_placeholder;
             }
        }

        async function fetchGithubRepos(repoIds) {
            try {
                const queryParts = repoIds.map(r => `repo:${r.id || r}`).join(' '); 
                const url = `https://api.github.com/search/repositories?q=${encodeURIComponent(queryParts)}&per_page=50`;
                const response = await fetch(url);
                if (response.status === 403) throw new Error("RATE_LIMIT");
                if (!response.ok) throw new Error("NET_ERR");
                const data = await response.json();
                return data.items || [];
            } catch (error) {
                console.error(error);
                if (error.message === "RATE_LIMIT") {
                    dom.apiStatusDot.classList.replace('bg-green-400', 'bg-red-500');
                    alert(I18N[currentLang].rate_limit);
                }
                return [];
            }
        }

        function renderRepoCard(repo, whyTextObj, index = 0) {
            const stars = repo.stargazers_count >= 1000 ? (repo.stargazers_count/1000).toFixed(1)+'k' : repo.stargazers_count;
            let desc = repo.description || "---";
            if(desc.length > 90) desc = desc.substring(0, 87) + "...";
            const delay = index * 50; 
            let insightHtml = '';
            if (whyTextObj && whyTextObj[currentLang]) {
                insightHtml = `<div class="insight-box mt-3 rounded"><span class="text-yellow-500 font-bold uppercase text-[10px]">${I18N[currentLang].insight_label}</span><br>${whyTextObj[currentLang]}</div>`;
            }
            return `
            <a href="${repo.html_url}" target="_blank" class="block group animate-entry h-full" style="animation-delay: ${delay}ms">
                <div class="bg-interactive p-5 rounded-lg h-full flex flex-col justify-between hover:border-cyan-400">
                    <div>
                        <div class="flex items-center gap-2 mb-2 opacity-70"><span class="w-1.5 h-1.5 bg-cyan-500 rounded-full"></span><span class="text-[10px] text-cyan-300 font-mono uppercase tracking-wider">${repo.owner.login}</span></div>
                        <h3 class="text-lg font-bold text-white group-hover:text-cyan-400 font-mono leading-tight mb-2 transition-colors">${repo.name}</h3>
                        <p class="text-xs text-gray-400 leading-relaxed font-sans border-b border-gray-800 pb-3 mb-1">${desc}</p>
                        ${insightHtml}
                    </div>
                    <div class="mt-3 flex items-center justify-between pt-1"><div class="flex gap-2">${repo.language ? `<span class="px-2 py-1 text-[10px] bg-gray-800 text-cyan-200 rounded border border-gray-600 font-bold uppercase">${repo.language}</span>` : ''}</div><span class="text-yellow-400 font-bold text-sm font-mono flex items-center gap-1">★ ${stars}</span></div>
                </div>
            </a>`;
        }
        
        function renderMCPGrid() {
            dom.mcpContainer.innerHTML = MCP_DATA.map((item, idx) => {
                const delay = idx * 50;
                return `
                <a href="${item.link}" target="_blank" class="block group animate-entry h-full" style="animation-delay: ${delay}ms">
                    <div class="bg-interactive p-5 rounded-lg h-full flex flex-col justify-between hover:border-yellow-400" style="border-left: 3px solid #FFD700;">
                        <div>
                            <div class="flex items-center gap-2 mb-2 opacity-70">
                                <span class="w-1.5 h-1.5 bg-yellow-500 rounded-full"></span>
                                <span class="text-[10px] text-yellow-300 font-mono uppercase tracking-wider">MCP SERVER</span>
                            </div>
                            <h3 class="text-lg font-bold text-white group-hover:text-yellow-400 font-mono leading-tight mb-2 transition-colors">${item.title}</h3>
                            <p class="text-xs text-gray-400 leading-relaxed font-sans pb-3 mb-1">${item.desc[currentLang]}</p>
                        </div>
                        <div class="mt-3 flex items-center justify-between pt-1">
                            <span class="px-2 py-1 text-[10px] bg-yellow-900/30 text-yellow-200 rounded border border-yellow-700/50 font-bold uppercase">PROTOCOL</span>
                            <span class="text-gray-500 text-[10px] font-mono flex items-center gap-1">SOURCE ↗</span>
                        </div>
                    </div>
                </a>`;
            }).join('');
        }

        function renderDocsGrid() {
            dom.docsContainer.innerHTML = DOCS_DATA.map((item, idx) => {
                const delay = idx * 50;
                return `
                <a href="${item.link}" target="_blank" class="block group animate-entry h-full" style="animation-delay: ${delay}ms">
                    <div class="bg-interactive p-5 rounded-lg h-full flex flex-col justify-between hover:border-purple-500" style="border-left: 3px solid #A855F7;">
                        <div>
                            <div class="flex items-center gap-2 mb-2 opacity-70">
                                <span class="w-1.5 h-1.5 bg-purple-500 rounded-full"></span>
                                <span class="text-[10px] text-purple-300 font-mono uppercase tracking-wider truncate">${item.linkText}</span>
                            </div>
                            <h3 class="text-xl font-bold text-white group-hover:text-purple-400 font-mono tracking-wide mb-1 transition-colors">${item.name}</h3>
                            
                            <div class="text-xs text-gray-400 leading-relaxed font-sans border-b border-gray-800 pb-3 mb-1">
                                <p class="mb-2"><strong class="text-purple-400/70 uppercase text-[9px]">Models:</strong> ${item.models}</p>
                                <p><strong class="text-purple-400/70 uppercase text-[9px]">Hosting:</strong> ${item.hosting}</p>
                            </div>
                        </div>
                        <div class="mt-3 flex items-center justify-between pt-1">
                            <span class="px-2 py-1 text-[10px] bg-purple-900/30 text-purple-200 rounded border border-purple-700/50 font-bold uppercase">MANUAL</span>
                            <span class="text-gray-500 text-[10px] font-mono flex items-center gap-1">VISIT DOCS ↗</span>
                        </div>
                    </div>
                </a>`;
            }).join('');
        }

        function updateExplorerContent(key) {
            const theme = REPO_THEMES[key];
            if (!theme) return;
            dom.resultsTitle.textContent = theme.label;
            dom.resultsSubtitle.textContent = `// ${theme.desc[currentLang]}`;
            dom.explorerBriefing.classList.remove('hidden');
            dom.explorerBriefingText.textContent = theme.briefing[currentLang];
            if(CACHE[key]) {
                dom.resultsContainer.innerHTML = CACHE[key].map((r, i) => {
                    const itemData = theme.items.find(item => item.id.toLowerCase() === r.full_name.toLowerCase());
                    return renderRepoCard(r, itemData ? itemData.why : null, i);
                }).join('');
            }
        }

        async function loadExplorerCategory(key) {
            document.querySelectorAll('#category-buttons .btn-category').forEach(b => { b.dataset.key === key ? b.classList.add('active') : b.classList.remove('active'); });
            if(CACHE[key]) { updateExplorerContent(key); return; }
            const theme = REPO_THEMES[key];
            updateExplorerContent(key);
            dom.resultsContainer.innerHTML = "";
            dom.spinnerExp.classList.remove('hidden');
            const repos = await fetchGithubRepos(theme.items);
            dom.spinnerExp.classList.add('hidden');
            if(repos.length) {
                repos.sort((a,b) => b.stargazers_count - a.stargazers_count);
                CACHE[key] = repos;
                updateExplorerContent(key);
            } else { dom.resultsContainer.innerHTML = `<div class='text-gray-500 font-mono p-4'>${I18N[currentLang].no_data}</div>`; }
        }

        function updateTitanContent(key) {
            const theme = TITAN_THEMES[key];
            if(!theme) return;
            dom.titanHeaderName.textContent = theme.label;
            dom.titanLogo.textContent = theme.label.substring(0,2);
            dom.titanBriefing.classList.remove('hidden');
            dom.titanBriefingTitle.textContent = `// ${theme.label} STRATEGY`;
            dom.titanBriefingText.textContent = theme.briefing[currentLang];
            const cacheKey = `titan_${key}`;
            if(CACHE[cacheKey]) {
                dom.titansContainer.innerHTML = CACHE[cacheKey].map((r, i) => {
                    const itemData = theme.items.find(item => item.id.toLowerCase() === r.full_name.toLowerCase());
                    return renderRepoCard(r, itemData ? itemData.why : null, i);
                }).join('');
            }
        }

        async function loadTitanCategory(key) {
             document.querySelectorAll('#titans-buttons .btn-category').forEach(b => { b.dataset.key === key ? b.classList.add('active') : b.classList.remove('active'); });
            const cacheKey = `titan_${key}`;
            if(CACHE[cacheKey]) { updateTitanContent(key); return; }
            const theme = TITAN_THEMES[key];
            updateTitanContent(key);
            dom.titansContainer.innerHTML = "";
            dom.spinnerTitans.classList.remove('hidden');
            const repos = await fetchGithubRepos(theme.items);
            dom.spinnerTitans.classList.add('hidden');
            if(repos.length) {
                repos.sort((a,b) => b.stargazers_count - a.stargazers_count);
                CACHE[cacheKey] = repos;
                updateTitanContent(key);
            } else { dom.titansContainer.innerHTML = `<div class='text-gray-500 font-mono p-4'>${I18N[currentLang].no_data}</div>`; }
        }

        function handleSearch() {
            const q = dom.searchInput.value.trim();
            if(!q) return;

            if (!dom.viewMcp.classList.contains('hidden')) {
                 const mcpQuery = `${q} "mcp server" OR "model context protocol"`;
                 window.open(`https://github.com/search?q=${encodeURIComponent(mcpQuery)}&type=repositories`, '_blank');
                 return;
            }

            document.querySelectorAll('#category-buttons .btn-category').forEach(b => b.classList.remove('active'));
            dom.resultsTitle.textContent = "DATABASE SEARCH";
            dom.resultsSubtitle.textContent = `// QUERY: "${q}"`;
            dom.explorerBriefing.classList.add('hidden');
            dom.spinnerExp.classList.remove('hidden');
            dom.resultsContainer.innerHTML = "";
            
            fetch(`https://api.github.com/search/repositories?q=${encodeURIComponent(q)}&sort=stars&order=desc&per_page=40`)
                .then(r => r.json())
                .then(d => {
                    dom.spinnerExp.classList.add('hidden');
                    if(d.items && d.items.length) {
                        dom.resultsContainer.innerHTML = d.items.map((r, i) => renderRepoCard(r, null, i)).join('');
                    } else {
                        dom.resultsContainer.innerHTML = `<div class='text-gray-500 font-mono'>${I18N[currentLang].no_result}</div>`;
                    }
                })
                .catch(e => {
                    dom.spinnerExp.classList.add('hidden');
                    console.error(e);
                });
        }

        // --- INIT ---
        function init() {
            // Setup View Switch
            dom.viewSelector.addEventListener('change', (e) => {
                const val = e.target.value;
                dom.viewExplorer.classList.add('hidden');
                dom.viewTitans.classList.add('hidden');
                dom.viewMcp.classList.add('hidden');
                dom.viewDocs.classList.add('hidden');

                if (val === 'explorer') {
                    dom.viewExplorer.classList.remove('hidden');
                } else if (val === 'titans') {
                    dom.viewTitans.classList.remove('hidden');
                    if(!document.querySelector('#titans-buttons .active')) loadTitanCategory('meta');
                } else if (val === 'mcp') {
                    dom.viewMcp.classList.remove('hidden');
                    renderMCPGrid();
                    dom.mcpBriefingText.textContent = I18N[currentLang].mcp_briefing;
                } else if (val === 'docs') {
                    dom.viewDocs.classList.remove('hidden');
                    renderDocsGrid();
                    dom.docsBriefingText.textContent = I18N[currentLang].docs_briefing;
                }
                updateSearchPlaceholder();
            });

            dom.btnOpenGuide.addEventListener('click', () => dom.modalGuide.classList.remove('hidden'));
            dom.btnCloseGuide.addEventListener('click', () => dom.modalGuide.classList.add('hidden'));
            dom.modalGuide.addEventListener('click', (e) => { if (e.target === dom.modalGuide) dom.modalGuide.classList.add('hidden'); });

            Object.keys(REPO_THEMES).forEach(key => {
                const btn = document.createElement('button'); btn.className = 'btn-category'; btn.textContent = REPO_THEMES[key].label.replace(/_/g, ' '); btn.dataset.key = key; btn.onclick = () => loadExplorerCategory(key); dom.expButtonsContainer.appendChild(btn);
            });
            Object.keys(TITAN_THEMES).forEach(key => {
                const btn = document.createElement('button'); btn.className = 'btn-category'; btn.textContent = TITAN_THEMES[key].label; btn.dataset.key = key; btn.onclick = () => loadTitanCategory(key); dom.titansButtonsContainer.appendChild(btn);
            });

            dom.executeButton.onclick = handleSearch;
            dom.searchInput.onkeydown = (e) => { if(e.key==='Enter') handleSearch(); };

            detectLanguage();
            loadExplorerCategory('core');
        }

        init();
    </script>
</body>
</html>